{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "from math import floor\n",
    "from Functions import *\n",
    "from multiprocessing import Pool\n",
    "import numba as nb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'trainingData'\n",
    "\n",
    "R = 2                           # Upscaling factor=2\n",
    "patchSize = 11                  # Pacth Size=11\n",
    "gradientSize = 9                # Gradient Size = 9\n",
    "Qangle = 24                     # Quantization factor of angle =24\n",
    "Qstrength = 3                   # Quantization factor of strength =3\n",
    "Qcoherence = 3                  # Quantization factor of coherence =3\n",
    "stre = np.zeros((Qstrength-1))  # Strength boundary\n",
    "cohe = np.zeros((Qcoherence-1)) # Coherence boundary\n",
    "\n",
    "Q = np.zeros((R*R, Qangle*Qstrength*Qcoherence, patchSize*patchSize, patchSize*patchSize))  # Eq.4\n",
    "V = np.zeros((R*R, Qangle*Qstrength*Qcoherence, patchSize*patchSize))                       # Eq.5\n",
    "h = np.zeros((R*R, Qangle*Qstrength*Qcoherence, patchSize*patchSize))\n",
    "mark = np.zeros((R*R, Qangle*Qstrength*Qcoherence))                  # statical distribution of patch numbers in each bucket\n",
    "w = Gaussian2d([patchSize, patchSize], 2)\n",
    "w = w/w.max()\n",
    "w = np.diag(w.ravel())                                               # Diagnal weighting matrix Wk in Algorithm 1\n",
    "\n",
    "filelist = make_dataset(trainPath)\n",
    "\n",
    "instance = 20000000                          # use 20000000 patches to get the Strength and coherence boundary\n",
    "\n",
    "patchNumber = 0                              # patch number has been used\n",
    "quantization = np.zeros((instance,2))        # quantization boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantization: Processing 10000000.0 patches (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"Functions.py\", line 130:\u001b[0m\n",
      "\u001b[1m@nb.jit(nopython=True, parallel=True)\n",
      "\u001b[1mdef Grad(patchX,patchY,weight):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  self.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantization: Processing 10000000.0 patches (1.4617%)\n",
      " Quantization: Processing 10000000.0 patches (2.9234%)\n",
      " Quantization: Processing 10000000.0 patches (4.3851%)\n",
      " Quantization: Processing 10000000.0 patches (5.8468%)\n",
      " Quantization: Processing 10000000.0 patches (7.3085%)\n",
      " Quantization: Processing 10000000.0 patches (8.7702%)\n",
      " Quantization: Processing 10000000.0 patches (10.2319%)\n",
      " Quantization: Processing 10000000.0 patches (11.6936%)\n",
      " Quantization: Processing 10000000.0 patches (13.1553%)\n",
      " Quantization: Processing 10000000.0 patches (14.617%)\n",
      " Quantization: Processing 10000000.0 patches (16.0787%)\n",
      " Quantization: Processing 10000000.0 patches (17.5404%)\n",
      " Quantization: Processing 10000000.0 patches (19.0021%)\n",
      " Quantization: Processing 10000000.0 patches (20.4638%)\n",
      " Quantization: Processing 10000000.0 patches (21.9255%)\n",
      " Quantization: Processing 10000000.0 patches (23.3872%)\n",
      " Quantization: Processing 10000000.0 patches (24.8489%)\n",
      " Quantization: Processing 10000000.0 patches (26.3106%)\n",
      " Quantization: Processing 10000000.0 patches (27.7723%)\n",
      " Quantization: Processing 10000000.0 patches (29.234%)\n",
      " Quantization: Processing 10000000.0 patches (30.6957%)\n",
      " Quantization: Processing 10000000.0 patches (32.1574%)\n",
      " Quantization: Processing 10000000.0 patches (33.6191%)\n",
      " Quantization: Processing 10000000.0 patches (35.0808%)\n",
      " Quantization: Processing 10000000.0 patches (36.5425%)\n",
      " Quantization: Processing 10000000.0 patches (38.0042%)\n",
      " Quantization: Processing 10000000.0 patches (39.4659%)\n",
      " Quantization: Processing 10000000.0 patches (40.9276%)\n",
      " Quantization: Processing 10000000.0 patches (42.3893%)\n",
      " Quantization: Processing 10000000.0 patches (43.851%)\n",
      " Quantization: Processing 10000000.0 patches (45.3127%)\n",
      " Quantization: Processing 10000000.0 patches (46.7744%)\n",
      " Quantization: Processing 10000000.0 patches (48.2361%)\n",
      " Quantization: Processing 10000000.0 patches (49.6978%)\n",
      " Quantization: Processing 10000000.0 patches (51.1595%)\n",
      " Quantization: Processing 10000000.0 patches (52.6212%)\n",
      " Quantization: Processing 10000000.0 patches (54.0829%)\n",
      " Quantization: Processing 10000000.0 patches (55.5446%)\n",
      " Quantization: Processing 10000000.0 patches (57.0063%)\n",
      " Quantization: Processing 10000000.0 patches (58.468%)\n",
      " Quantization: Processing 10000000.0 patches (59.9297%)\n",
      " Quantization: Processing 10000000.0 patches (61.3914%)\n",
      " Quantization: Processing 10000000.0 patches (62.8531%)\n",
      " Quantization: Processing 10000000.0 patches (64.3148%)\n",
      " Quantization: Processing 10000000.0 patches (65.7765%)\n",
      " Quantization: Processing 10000000.0 patches (67.2382%)\n",
      " Quantization: Processing 10000000.0 patches (68.6999%)\n",
      " Quantization: Processing 10000000.0 patches (70.1616%)\n",
      " Quantization: Processing 10000000.0 patches (71.6233%)\n",
      " Quantization: Processing 10000000.0 patches (73.085%)\n",
      " Quantization: Processing 10000000.0 patches (74.5467%)\n",
      " Quantization: Processing 10000000.0 patches (76.0084%)\n",
      " Quantization: Processing 10000000.0 patches (77.4701%)\n",
      " Quantization: Processing 10000000.0 patches (78.9318%)\n",
      " Quantization: Processing 10000000.0 patches (80.3935%)\n",
      " Quantization: Processing 10000000.0 patches (81.8552%)\n",
      " Quantization: Processing 10000000.0 patches (83.3169%)\n",
      " Quantization: Processing 10000000.0 patches (84.7786%)\n",
      " Quantization: Processing 10000000.0 patches (86.2403%)\n",
      " Quantization: Processing 10000000.0 patches (87.702%)\n",
      " Quantization: Processing 10000000.0 patches (89.1637%)\n",
      " Quantization: Processing 10000000.0 patches (90.6254%)\n",
      " Quantization: Processing 10000000.0 patches (92.0871%)\n",
      " Quantization: Processing 10000000.0 patches (93.5488%)\n",
      " Quantization: Processing 10000000.0 patches (95.0105%)\n",
      " Quantization: Processing 10000000.0 patches (96.4722%)\n",
      " Quantization: Processing 10000000.0 patches (97.9339%)\n",
      " Quantization: Processing 10000000.0 patches (99.3956%)\n",
      " done\n"
     ]
    }
   ],
   "source": [
    "for image in filelist:\n",
    "    print('\\r', end='')\n",
    "    print('' * 60, end='')\n",
    "    print('\\r Quantization: Processing '+ str(instance/2) + ' patches (' + str(200*patchNumber/instance) + '%)')\n",
    "    im_uint8 = cv2.imread(image)\n",
    "    if is_greyimage(im_uint8):\n",
    "        im_uint8 = im_uint8[:,:,0]\n",
    "    if len(im_uint8.shape)>2:\n",
    "        im_ycbcr = BGR2YCbCr(im_uint8)\n",
    "        im = im_ycbcr[:,:,0]\n",
    "    else:\n",
    "        im = im_uint8\n",
    "    im = modcrop(im,R)\n",
    "    im_LR = Prepare(im,patchSize,R)         # Prepare the cheap-upscaling images (optional: JPEG compression)\n",
    "    im_GX,im_GY = np.gradient(im_LR)        # Calculate the gradient images\n",
    "    quantization, patchNumber = QuantizationProcess (im_GX, im_GY,patchSize, patchNumber, w, quantization)  # get the strength and coherence of each patch\n",
    "    if (patchNumber > instance/2):\n",
    "        break\n",
    "print('\\r done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform quantization of patches, get the optimized strength and coherence boundaries\n",
    "quantization = quantization [0:patchNumber,:]\n",
    "quantization = np.sort(quantization,axis=0)\n",
    "for i in range(Qstrength-1):\n",
    "    stre[i] = quantization[floor((i+1)*patchNumber/Qstrength),0]\n",
    "for i in range(Qcoherence-1):\n",
    "    cohe[i] = quantization[floor((i+1)*patchNumber/Qcoherence),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to process images:\n",
      " Processing 1/200 image (trainingData/157036.jpg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"Functions.py\", line 145:\u001b[0m\n",
      "\u001b[1m@nb.jit(nopython=True, parallel=True)\n",
      "\u001b[1mdef HashTable(patchX,patchY,weight, Qangle,Qstrength,Qcoherence,stre,cohe):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  self.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 2/200 image (trainingData/187029.jpg)\n",
      " Processing 3/200 image (trainingData/71046.jpg)\n",
      " Processing 4/200 image (trainingData/299091.jpg)\n",
      " Processing 5/200 image (trainingData/242078.jpg)\n",
      " Processing 6/200 image (trainingData/232038.jpg)\n",
      " Processing 7/200 image (trainingData/173036.jpg)\n",
      " Processing 8/200 image (trainingData/198054.jpg)\n",
      " Processing 9/200 image (trainingData/388016.jpg)\n",
      " Processing 10/200 image (trainingData/292066.jpg)\n",
      " Processing 11/200 image (trainingData/189011.jpg)\n",
      " Processing 12/200 image (trainingData/59078.jpg)\n",
      " Processing 13/200 image (trainingData/108041.jpg)\n",
      " Processing 14/200 image (trainingData/66075.jpg)\n",
      " Processing 15/200 image (trainingData/20008.jpg)\n",
      " Processing 16/200 image (trainingData/370036.jpg)\n",
      " Processing 17/200 image (trainingData/41025.jpg)\n",
      " Processing 18/200 image (trainingData/207056.jpg)\n",
      " Processing 19/200 image (trainingData/314016.jpg)\n",
      " Processing 20/200 image (trainingData/188091.jpg)\n",
      " Processing 21/200 image (trainingData/56028.jpg)\n",
      " Processing 22/200 image (trainingData/134008.jpg)\n",
      " Processing 23/200 image (trainingData/153093.jpg)\n",
      " Processing 24/200 image (trainingData/54005.jpg)\n",
      " Processing 25/200 image (trainingData/65019.jpg)\n",
      " Processing 26/200 image (trainingData/176039.jpg)\n",
      " Processing 27/200 image (trainingData/187003.jpg)\n",
      " Processing 28/200 image (trainingData/61086.jpg)\n",
      " Processing 29/200 image (trainingData/147021.jpg)\n",
      " Processing 30/200 image (trainingData/353013.jpg)\n",
      " Processing 31/200 image (trainingData/317080.jpg)\n",
      " Processing 32/200 image (trainingData/28096.jpg)\n",
      " Processing 33/200 image (trainingData/35010.jpg)\n",
      " Processing 34/200 image (trainingData/151087.jpg)\n",
      " Processing 35/200 image (trainingData/254033.jpg)\n",
      " Processing 36/200 image (trainingData/189003.jpg)\n",
      " Processing 37/200 image (trainingData/144067.jpg)\n",
      " Processing 38/200 image (trainingData/33066.jpg)\n",
      " Processing 39/200 image (trainingData/138032.jpg)\n",
      " Processing 40/200 image (trainingData/15088.jpg)\n",
      " Processing 41/200 image (trainingData/249061.jpg)\n",
      " Processing 42/200 image (trainingData/68077.jpg)\n",
      " Processing 43/200 image (trainingData/368078.jpg)\n",
      " Processing 44/200 image (trainingData/187039.jpg)\n",
      " Processing 45/200 image (trainingData/87065.jpg)\n",
      " Processing 46/200 image (trainingData/216066.jpg)\n",
      " Processing 47/200 image (trainingData/43083.jpg)\n",
      " Processing 48/200 image (trainingData/372047.jpg)\n",
      " Processing 49/200 image (trainingData/227046.jpg)\n",
      " Processing 50/200 image (trainingData/15004.jpg)\n",
      " Processing 51/200 image (trainingData/236017.jpg)\n",
      " Processing 52/200 image (trainingData/310007.jpg)\n",
      " Processing 53/200 image (trainingData/198023.jpg)\n",
      " Processing 54/200 image (trainingData/22093.jpg)\n",
      " Processing 55/200 image (trainingData/106025.jpg)\n",
      " Processing 56/200 image (trainingData/202012.jpg)\n",
      " Processing 57/200 image (trainingData/159045.jpg)\n",
      " Processing 58/200 image (trainingData/376020.jpg)\n",
      " Processing 59/200 image (trainingData/124084.jpg)\n",
      " Processing 60/200 image (trainingData/254054.jpg)\n",
      " Processing 61/200 image (trainingData/25098.jpg)\n",
      " Processing 62/200 image (trainingData/8049.jpg)\n",
      " Processing 63/200 image (trainingData/104022.jpg)\n",
      " Processing 64/200 image (trainingData/238011.jpg)\n",
      " Processing 65/200 image (trainingData/285036.jpg)\n",
      " Processing 66/200 image (trainingData/65132.jpg)\n",
      " Processing 67/200 image (trainingData/326038.jpg)\n",
      " Processing 68/200 image (trainingData/22090.jpg)\n",
      " Processing 69/200 image (trainingData/159091.jpg)\n",
      " Processing 70/200 image (trainingData/76002.jpg)\n",
      " Processing 71/200 image (trainingData/227040.jpg)\n",
      " Processing 72/200 image (trainingData/145053.jpg)\n",
      " Processing 73/200 image (trainingData/374020.jpg)\n",
      " Processing 74/200 image (trainingData/46076.jpg)\n",
      " Processing 75/200 image (trainingData/100080.jpg)\n",
      " Processing 76/200 image (trainingData/113016.jpg)\n",
      " Processing 77/200 image (trainingData/134052.jpg)\n",
      " Processing 78/200 image (trainingData/311068.jpg)\n",
      " Processing 79/200 image (trainingData/239096.jpg)\n",
      " Processing 80/200 image (trainingData/187071.jpg)\n",
      " Processing 81/200 image (trainingData/16052.jpg)\n",
      " Processing 82/200 image (trainingData/94079.jpg)\n",
      " Processing 83/200 image (trainingData/311081.jpg)\n",
      " Processing 84/200 image (trainingData/118035.jpg)\n",
      " Processing 85/200 image (trainingData/130034.jpg)\n",
      " Processing 86/200 image (trainingData/138078.jpg)\n",
      " Processing 87/200 image (trainingData/35070.jpg)\n",
      " Processing 88/200 image (trainingData/35058.jpg)\n",
      " Processing 89/200 image (trainingData/260081.jpg)\n",
      " Processing 90/200 image (trainingData/246053.jpg)\n",
      " Processing 91/200 image (trainingData/26031.jpg)\n",
      " Processing 92/200 image (trainingData/67079.jpg)\n",
      " Processing 93/200 image (trainingData/164074.jpg)\n",
      " Processing 94/200 image (trainingData/95006.jpg)\n",
      " Processing 95/200 image (trainingData/27059.jpg)\n",
      " Processing 96/200 image (trainingData/66039.jpg)\n",
      " Processing 97/200 image (trainingData/112082.jpg)\n",
      " Processing 98/200 image (trainingData/140075.jpg)\n",
      " Processing 99/200 image (trainingData/106020.jpg)\n",
      " Processing 100/200 image (trainingData/97017.jpg)\n",
      " Processing 101/200 image (trainingData/302003.jpg)\n",
      " Processing 102/200 image (trainingData/118020.jpg)\n",
      " Processing 103/200 image (trainingData/365073.jpg)\n",
      " Processing 104/200 image (trainingData/178054.jpg)\n",
      " Processing 105/200 image (trainingData/216053.jpg)\n",
      " Processing 106/200 image (trainingData/268002.jpg)\n",
      " Processing 107/200 image (trainingData/368016.jpg)\n",
      " Processing 108/200 image (trainingData/117054.jpg)\n",
      " Processing 109/200 image (trainingData/277095.jpg)\n",
      " Processing 110/200 image (trainingData/274007.jpg)\n",
      " Processing 111/200 image (trainingData/385028.jpg)\n",
      " Processing 112/200 image (trainingData/48055.jpg)\n",
      " Processing 113/200 image (trainingData/286092.jpg)\n",
      " Processing 114/200 image (trainingData/23025.jpg)\n",
      " Processing 115/200 image (trainingData/24004.jpg)\n",
      " Processing 116/200 image (trainingData/323016.jpg)\n",
      " Processing 117/200 image (trainingData/271008.jpg)\n",
      " Processing 118/200 image (trainingData/376001.jpg)\n",
      " Processing 119/200 image (trainingData/187083.jpg)\n",
      " Processing 120/200 image (trainingData/161062.jpg)\n",
      " Processing 121/200 image (trainingData/188005.jpg)\n",
      " Processing 122/200 image (trainingData/100098.jpg)\n",
      " Processing 123/200 image (trainingData/135037.jpg)\n",
      " Processing 124/200 image (trainingData/309004.jpg)\n",
      " Processing 125/200 image (trainingData/169012.jpg)\n",
      " Processing 126/200 image (trainingData/231015.jpg)\n",
      " Processing 127/200 image (trainingData/166081.jpg)\n",
      " Processing 128/200 image (trainingData/271031.jpg)\n",
      " Processing 129/200 image (trainingData/216041.jpg)\n",
      " Processing 130/200 image (trainingData/181018.jpg)\n",
      " Processing 131/200 image (trainingData/163062.jpg)\n",
      " Processing 132/200 image (trainingData/35091.jpg)\n",
      " Processing 133/200 image (trainingData/198004.jpg)\n",
      " Processing 134/200 image (trainingData/196015.jpg)\n",
      " Processing 135/200 image (trainingData/172032.jpg)\n",
      " Processing 136/200 image (trainingData/12003.jpg)\n",
      " Processing 137/200 image (trainingData/147062.jpg)\n",
      " Processing 138/200 image (trainingData/105053.jpg)\n",
      " Processing 139/200 image (trainingData/43070.jpg)\n",
      " Processing 140/200 image (trainingData/65074.jpg)\n",
      " Processing 141/200 image (trainingData/78019.jpg)\n",
      " Processing 142/200 image (trainingData/140055.jpg)\n",
      " Processing 143/200 image (trainingData/100075.jpg)\n",
      " Processing 144/200 image (trainingData/113009.jpg)\n",
      " Processing 145/200 image (trainingData/155060.jpg)\n",
      " Processing 146/200 image (trainingData/60079.jpg)\n",
      " Processing 147/200 image (trainingData/23084.jpg)\n",
      " Processing 148/200 image (trainingData/249087.jpg)\n",
      " Processing 149/200 image (trainingData/183087.jpg)\n",
      " Processing 150/200 image (trainingData/45077.jpg)\n",
      " Processing 151/200 image (trainingData/22013.jpg)\n",
      " Processing 152/200 image (trainingData/209070.jpg)\n",
      " Processing 153/200 image (trainingData/55067.jpg)\n",
      " Processing 154/200 image (trainingData/245051.jpg)\n",
      " Processing 155/200 image (trainingData/239007.jpg)\n",
      " Processing 156/200 image (trainingData/176019.jpg)\n",
      " Processing 157/200 image (trainingData/8143.jpg)\n",
      " Processing 158/200 image (trainingData/103041.jpg)\n",
      " Processing 159/200 image (trainingData/145014.jpg)\n",
      " Processing 160/200 image (trainingData/113044.jpg)\n",
      " Processing 161/200 image (trainingData/374067.jpg)\n",
      " Processing 162/200 image (trainingData/41004.jpg)\n",
      " Processing 163/200 image (trainingData/109034.jpg)\n",
      " Processing 164/200 image (trainingData/35008.jpg)\n",
      " Processing 165/200 image (trainingData/246016.jpg)\n",
      " Processing 166/200 image (trainingData/135069.jpg)\n",
      " Processing 167/200 image (trainingData/225017.jpg)\n",
      " Processing 168/200 image (trainingData/361084.jpg)\n",
      " Processing 169/200 image (trainingData/61060.jpg)\n",
      " Processing 170/200 image (trainingData/253036.jpg)\n",
      " Processing 171/200 image (trainingData/65010.jpg)\n",
      " Processing 172/200 image (trainingData/105019.jpg)\n",
      " Processing 173/200 image (trainingData/90076.jpg)\n",
      " Processing 174/200 image (trainingData/42078.jpg)\n",
      " Processing 175/200 image (trainingData/42044.jpg)\n",
      " Processing 176/200 image (trainingData/156079.jpg)\n",
      " Processing 177/200 image (trainingData/188063.jpg)\n",
      " Processing 178/200 image (trainingData/126039.jpg)\n",
      " Processing 179/200 image (trainingData/28075.jpg)\n",
      " Processing 180/200 image (trainingData/55075.jpg)\n",
      " Processing 181/200 image (trainingData/122048.jpg)\n",
      " Processing 182/200 image (trainingData/163014.jpg)\n",
      " Processing 183/200 image (trainingData/181091.jpg)\n",
      " Processing 184/200 image (trainingData/170054.jpg)\n",
      " Processing 185/200 image (trainingData/301007.jpg)\n",
      " Processing 186/200 image (trainingData/12074.jpg)\n",
      " Processing 187/200 image (trainingData/247085.jpg)\n",
      " Processing 188/200 image (trainingData/293029.jpg)\n",
      " Processing 189/200 image (trainingData/176035.jpg)\n",
      " Processing 190/200 image (trainingData/80099.jpg)\n",
      " Processing 191/200 image (trainingData/159029.jpg)\n",
      " Processing 192/200 image (trainingData/24063.jpg)\n",
      " Processing 193/200 image (trainingData/183055.jpg)\n",
      " Processing 194/200 image (trainingData/2092.jpg)\n",
      " Processing 195/200 image (trainingData/181079.jpg)\n",
      " Processing 196/200 image (trainingData/92059.jpg)\n",
      " Processing 197/200 image (trainingData/108073.jpg)\n",
      " Processing 198/200 image (trainingData/153077.jpg)\n",
      " Processing 199/200 image (trainingData/23080.jpg)\n",
      " Processing 200/200 image (trainingData/365025.jpg)\n",
      "9785.323970079422\n"
     ]
    }
   ],
   "source": [
    "print('Begin to process images:')\n",
    "start = time.time()\n",
    "imagecount = 1\n",
    "for image in filelist:\n",
    "    print('\\r', end='')\n",
    "    print('' * 60, end='')\n",
    "    print('\\r Processing ' + str(imagecount) +'/' + str(len(filelist))+ ' image ('   + image + ')')\n",
    "    \n",
    "    im_uint8 = cv2.imread(image)\n",
    "    if is_greyimage(im_uint8):\n",
    "        im_uint8 = im_uint8[:,:,0]\n",
    "    if len(im_uint8.shape)>2:\n",
    "        im_ycbcr = BGR2YCbCr(im_uint8)\n",
    "        im = im_ycbcr[:,:,0]\n",
    "    else:\n",
    "        im = im_uint8\n",
    "    im = modcrop(im,R)\n",
    "    im_LR = Prepare(im,patchSize,R)\n",
    "    im_HR = im2double(im)\n",
    "    #im_HR = Dog1(im_HR)                # optional: sharpen the image\n",
    "    im_GX,im_GY = np.gradient(im_LR)\n",
    "    Q, V, mark = TrainProcessSMC(im_LR, im_HR, im_GX, im_GY,patchSize, w, Qangle, Qstrength,Qcoherence, stre, cohe, R, Q, V, mark)  # get Q, V of each patch\n",
    "    imagecount += 1\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using patch symmetry for nearly 8* more learning examples: \n"
     ]
    }
   ],
   "source": [
    "# optional: Using patch symmetry for nearly 8* more learning examples\n",
    "print('\\r', end='')\n",
    "print(' ' * 60, end='')\n",
    "print('\\r Using patch symmetry for nearly 8* more learning examples:')\n",
    "for i in range(Qangle):\n",
    "    for j in range(Qstrength*Qcoherence):\n",
    "        for r in range(R*R):\n",
    "            for t in range(1,8):\n",
    "                t1 = t % 4\n",
    "                t2 = floor(t / 4)\n",
    "                Q1 = Getfromsymmetry1(Q[r, i * Qstrength * Qcoherence + j], patchSize, t1, t2)  # Rotate 90*t1 degree or flip t2\n",
    "                V1 = Getfromsymmetry2(V[r, i * Qstrength * Qcoherence + j], patchSize, t1, t2)\n",
    "                i1 = Qangle*t1/2 + i\n",
    "                i1 = np.int(i1)\n",
    "                if t2 == 1:\n",
    "                    i1 = Qangle -1 - i1\n",
    "                while i1 >= Qangle:\n",
    "                    i1 = i1 - Qangle\n",
    "                while i1 < 0:\n",
    "                    i1 = i1 + Qangle\n",
    "                Q[r, i1 * Qstrength * Qcoherence + j] += Q1\n",
    "                V[r, i1 * Qstrength * Qcoherence + j] += V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrent trainning mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConcurenrtTrainprocessSMC(i):\n",
    "    if (i < iteration - 1):\n",
    "        offset_i = offset[i * batch:i * batch + batch]\n",
    "        offset2_i = offset2[i * batch:i * batch + batch]\n",
    "        grid = np.tile(gridon[..., None], [1, 1, batch]) + np.tile(offset_i, [patchSize, patchSize, 1])\n",
    "    else:\n",
    "        offset_i = offset[i * batch:im.size]\n",
    "        offset2_i = offset2[i * batch:im.size]\n",
    "        grid = np.tile(gridon[..., None], [1, 1, im.size - (iteration - 1) * batch]) + np.tile(offset_i,[patchSize, patchSize,1])\n",
    "    f = im_LR.ravel()[grid]\n",
    "    gx = im_GX.ravel()[grid]\n",
    "    gy = im_GY.ravel()[grid]\n",
    "    gx = gx.reshape((1, patchSize * patchSize, gx.shape[2]))\n",
    "    gy = gy.reshape((1, patchSize * patchSize, gy.shape[2]))\n",
    "    G = np.vstack((gx, gy))\n",
    "    g1 = np.transpose(G, (2, 0, 1))\n",
    "    g2 = np.transpose(G, (2, 1, 0))\n",
    "    x = Gaussian_Mul(g1, g2, wGaussian)\n",
    "    w, v = np.linalg.eig(x)\n",
    "    idx = (-w).argsort()\n",
    "    w = w[np.arange(np.shape(w)[0])[:, np.newaxis], idx]\n",
    "    v = v[np.arange(np.shape(v)[0])[:, np.newaxis, np.newaxis], np.arange(np.shape(v)[1])[np.newaxis, :, np.newaxis], idx[:,np.newaxis,:]]\n",
    "    thelta = np.arctan(v[:, 1, 0] / v[:, 0, 0])\n",
    "    thelta[thelta < 0] = thelta[thelta < 0] + pi\n",
    "    thelta = np.floor(thelta / (pi / Qangle))\n",
    "    thelta[thelta > Qangle - 1] = Qangle - 1\n",
    "    thelta[thelta < 0] = 0\n",
    "    lamda = w[:, 0]\n",
    "    u = (np.sqrt(w[:, 0]) - np.sqrt(w[:, 1])) / (np.sqrt(w[:, 0]) + np.sqrt(w[:, 1]) + 0.00000000000000001)\n",
    "    lamda = np.searchsorted(stre, lamda)\n",
    "    u = np.searchsorted(cohe, u)\n",
    "    j = thelta * Qstrength * Qcoherence + lamda * Qcoherence + u\n",
    "    j = j.astype('int')\n",
    "    \n",
    "    f_vec = np.reshape(f, (patchSize * patchSize, -1)) - mean\n",
    "    f_vec_reduced = np.dot(pca_matrix, f_vec)\n",
    "    t = kmeans.predict(f_vec_reduced.reshape(-1, 1))\n",
    "    \n",
    "    f = f.reshape(-1, patchSize*patchSize)\n",
    "    A = np.dot(f.T, f)\n",
    "        \n",
    "    Ql = np.zeros((R*R, Qangle*Qstrength*Qcoherence, patchSize*patchSize, patchSize*patchSize))  # Eq.4\n",
    "    Vl = np.zeros((R*R, Qangle*Qstrength*Qcoherence, patchSize*patchSize))                       # Eq.5\n",
    "        \n",
    "    Ql[t,j] += A\n",
    "    im_HR_f = im_HR.ravel()[grid].reshape(patchSize*patchSize, -1)\n",
    "    b1 = f.T * im_HR_f\n",
    "    b = b1.reshape(-1, patchSize*patchSize)\n",
    "    Vl[t,j] += b\n",
    "#     mark[t,j] = mark[t,j]+1\n",
    "    \n",
    "    return Ql, Vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to process images:\n",
      " Processing 1/4 image (trainingDataSmall/153093.jpg)\n",
      "Con out\n",
      "29.007375955581665\n",
      " Processing 2/4 image (trainingDataSmall/169012.jpg)\n",
      "Con out\n",
      "48.211426734924316\n",
      " Processing 3/4 image (trainingDataSmall/176019.jpg)\n",
      "Con out\n",
      "44.54947304725647\n",
      " Processing 4/4 image (trainingDataSmall/181079.jpg)\n",
      "Con out\n",
      "39.375470876693726\n"
     ]
    }
   ],
   "source": [
    "# 并发方式\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Begin to process images:')\n",
    "imagecount = 1\n",
    "wGaussian = Gaussian2d([patchSize, patchSize], 2)\n",
    "wGaussian = wGaussian/wGaussian.max()\n",
    "wGaussian = np.diag(wGaussian.ravel())\n",
    "for image in filelist:\n",
    "    print('\\r', end='')\n",
    "    print('' * 60, end='')\n",
    "    print('\\r Processing ' + str(imagecount) +'/' + str(len(filelist))+ ' image ('   + image + ')')\n",
    "    start = time.time()\n",
    "    im_uint8 = cv2.imread(image)\n",
    "    if is_greyimage(im_uint8):\n",
    "        im_uint8 = im_uint8[:,:,0]\n",
    "    if len(im_uint8.shape)>2:\n",
    "        im_ycbcr = BGR2YCbCr(im_uint8)\n",
    "        im = im_ycbcr[:,:,0]\n",
    "    else:\n",
    "        im = im_uint8\n",
    "    im = modcrop(im,R)\n",
    "    H, W = im.shape\n",
    "    im_LR = Prepare(im,patchSize,R)\n",
    "    im_HR = im2double(im)\n",
    "    #im_HR = Dog1(im_HR)                # optional: sharpen the image\n",
    "    im_GX,im_GY = np.gradient(im_LR)\n",
    "    index = np.array(range(im_LR.size)).reshape(im_LR.shape)\n",
    "    offset = np.array(index[0:H, 0:W].ravel())\n",
    "    offset2 = np.array(range(im.size))\n",
    "    gridon = index[0:patchSize, 0:patchSize]\n",
    "    batch = 2000\n",
    "    iteration = ceil(im.size / batch + 0.000000000000001)\n",
    "    i = range(iteration - 5)\n",
    "    p = Pool()\n",
    "    ret = p.map(ConcurenrtTrainprocessSMC, i)\n",
    "    print('Con out')\n",
    "    \n",
    "    for i in range(iteration - 5):\n",
    "        Q += np.array(ret[i][0])\n",
    "        V += np.array(ret[i][1])\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "#     Q, V, mark = TrainProcessSMC(im_LR, im_HR, im_GX, im_GY,patchSize, w, Qangle, Qstrength,Qcoherence, stre, cohe, R, Q, V, mark)  # get Q, V of each patch\n",
    "    imagecount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 216, 121)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(kmeans.labels_==0)/kmeans.labels_.shape[0]\n",
    "array = np.array(ret[5][1])\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the filter of RAISR:\n",
      "Type: 0\n",
      "Type: 1\n",
      "Type: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py:2093: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: 3\n",
      "Type: 4\n",
      "Type: 5\n",
      "Type: 6\n",
      "Type: 7\n",
      "Type: 8\n",
      "Saving...\n",
      "Finished.                                                   \n"
     ]
    }
   ],
   "source": [
    "print('Get the filter of RAISR:')\n",
    "for t in range(R*R):\n",
    "    print('\\rType: '+str(t))\n",
    "    for j in range(Qangle*Qstrength*Qcoherence):\n",
    "        while(True):\n",
    "            if(Q[t,j].sum()<100):\n",
    "                break\n",
    "            if(np.linalg.det(Q[t,j])<1):\n",
    "                Q[t,j] = Q[t,j] + np.eye(patchSize*patchSize)* Q[t,j].sum()*0.000000005\n",
    "            else:\n",
    "                h[t,j] = np.linalg.inv(Q[t,j]).dot(V[t,j])         # Eq.2\n",
    "                break\n",
    "\n",
    "                \n",
    "print('Saving...')\n",
    "with open(\"Filters/Ckmeans_filter\"+str(R), \"wb\") as fp:\n",
    "    pickle.dump(h, fp)\n",
    "\n",
    "with open(\"Filters/Ckmeans_Qfactor_str\"+str(R), \"wb\") as sp:\n",
    "    pickle.dump(stre, sp)\n",
    "\n",
    "with open(\"Filters/Ckmeans_Qfactor_coh\"+str(R), \"wb\") as cp:\n",
    "    pickle.dump(cohe, cp)\n",
    "\n",
    "\n",
    "print('\\r', end='')\n",
    "print(' ' * 60, end='')\n",
    "print('\\rFinished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 5648835.38434242  5645236.33128634  5641376.31066372 ...\n",
      "     5629358.96675032  5630151.76793448  5631359.79393983]\n",
      "   [ 5645236.33128634  5644013.02109747  5641364.44573461 ...\n",
      "     5628141.33210211  5628947.74678882  5630149.81537777]\n",
      "   [ 5641376.31066372  5641364.44573461  5640792.19197018 ...\n",
      "     5627323.07909169  5628139.89117938  5629355.54729626]\n",
      "   ...\n",
      "   [ 5629358.96675032  5628141.33210211  5627323.07909169 ...\n",
      "     5640839.31861377  5641410.05646895  5641419.83261681]\n",
      "   [ 5630151.76793448  5628947.74678882  5628139.89117938 ...\n",
      "     5641410.05646895  5644056.86643388  5645277.84693416]\n",
      "   [ 5631359.79393983  5630149.81537777  5629355.54729626 ...\n",
      "     5641419.83261681  5645277.84693416  5648873.91452312]]\n",
      "\n",
      "  [[ 6749254.57499163  6744915.3770526   6740762.77107051 ...\n",
      "     6716581.3056967   6717849.39753831  6719915.38772665]\n",
      "   [ 6744915.3770526   6742929.31942837  6739987.28468809 ...\n",
      "     6714546.41379353  6715804.60273629  6717847.42343604]\n",
      "   [ 6740762.77107051  6739987.28468809  6739067.2193592  ...\n",
      "     6713288.71449331  6714542.38254401  6716575.29533145]\n",
      "   ...\n",
      "   [ 6716581.3056967   6714546.41379353  6713288.71449331 ...\n",
      "     6739102.7197975   6740018.90168156  6740792.63581484]\n",
      "   [ 6717849.39753831  6715804.60273629  6714542.38254401 ...\n",
      "     6740018.90168156  6742956.75639876  6744940.87063199]\n",
      "   [ 6719915.38772665  6717847.42343604  6716575.29533145 ...\n",
      "     6740792.63581484  6744940.87063199  6749277.65405353]]\n",
      "\n",
      "  [[ 4946738.40964097  4943946.5177996   4941527.37620801 ...\n",
      "     4899971.64716614  4900970.40836569  4902536.68811961]\n",
      "   [ 4943946.5177996   4942257.00110581  4940363.12462773 ...\n",
      "     4898407.659669    4899403.76916535  4900967.93963828]\n",
      "   [ 4941527.37620801  4940363.12462773  4939387.31289355 ...\n",
      "     4897407.55552443  4898406.62020725  4899968.15553985]\n",
      "   ...\n",
      "   [ 4899971.64716614  4898407.659669    4897407.55552443 ...\n",
      "     4939174.88868747  4940149.82214407  4941311.78597348]\n",
      "   [ 4900970.40836569  4899403.76916535  4898406.62020725 ...\n",
      "     4940149.82214407  4942042.61832996  4943729.65010256]\n",
      "   [ 4902536.68811961  4900967.93963828  4899968.15553985 ...\n",
      "     4941311.78597348  4943729.65010256  4946518.6744622 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1073381.25204147  1058976.87301806  1035595.6502422  ...\n",
      "      954280.028589     959273.90920415   964451.26437524]\n",
      "   [ 1058976.87301806  1061132.44521332  1047570.09504035 ...\n",
      "      952213.49865436   955501.19329488   959273.90920415]\n",
      "   [ 1035595.6502422   1047570.09504035  1050500.28482885 ...\n",
      "      949300.94892733   952213.49865436   954280.028589  ]\n",
      "   ...\n",
      "   [  954280.028589     952213.49865436   949300.94892733 ...\n",
      "     1050500.28482885  1047570.09504035  1035595.6502422 ]\n",
      "   [  959273.90920415   955501.19329488   952213.49865436 ...\n",
      "     1047570.09504035  1061132.44521332  1058976.87301806]\n",
      "   [  964451.26437524   959273.90920415   954280.028589   ...\n",
      "     1035595.6502422   1058976.87301806  1073381.25204147]]\n",
      "\n",
      "  [[ 1999359.91737001  1987816.4159476   1970377.03240285 ...\n",
      "     1780358.5968781   1776816.59212607  1779329.50843517]\n",
      "   [ 1987816.4159476   1997043.91776988  1992945.08249124 ...\n",
      "     1777330.89185694  1773910.65836213  1776816.59212607]\n",
      "   [ 1970377.03240285  1992945.08249124  2009554.24481332 ...\n",
      "     1780689.66403686  1777330.89185694  1780358.5968781 ]\n",
      "   ...\n",
      "   [ 1780358.5968781   1777330.89185694  1780689.66403686 ...\n",
      "     2009554.24481332  1992945.08249124  1970377.03240285]\n",
      "   [ 1776816.59212607  1773910.65836213  1777330.89185694 ...\n",
      "     1992945.08249124  1997043.91776988  1987816.4159476 ]\n",
      "   [ 1779329.50843517  1776816.59212607  1780358.5968781  ...\n",
      "     1970377.03240285  1987816.4159476   1999359.91737001]]\n",
      "\n",
      "  [[ 5597134.22154396  5601397.06217617  5597423.56553633 ...\n",
      "     4614980.17373315  4607172.87806221  4604668.19223371]\n",
      "   [ 5601397.06217617  5630280.2556385   5642192.52792011 ...\n",
      "     4617124.15304889  4609404.44355245  4607172.87806221]\n",
      "   [ 5597423.56553633  5642192.52792011  5676589.4693255  ...\n",
      "     4624848.48347559  4617124.15304889  4614980.17373315]\n",
      "   ...\n",
      "   [ 4614980.17373315  4617124.15304889  4624848.48347559 ...\n",
      "     5676589.4693255   5642192.52792011  5597423.56553633]\n",
      "   [ 4607172.87806221  4609404.44355245  4617124.15304889 ...\n",
      "     5642192.52792011  5630280.2556385   5601397.06217617]\n",
      "   [ 4604668.19223371  4607172.87806221  4614980.17373315 ...\n",
      "     5597423.56553633  5601397.06217617  5597134.22154396]]]\n",
      "\n",
      "\n",
      " [[[13735047.88842616 13736969.44698069 13736927.02314381 ...\n",
      "    13726172.51118699 13723624.5321328  13719598.16982594]\n",
      "   [13736969.44698069 13741074.40258229 13742055.59052548 ...\n",
      "    13730223.92868797 13727667.85616194 13723624.60196747]\n",
      "   [13736927.02314381 13742055.59052548 13744844.32641154 ...\n",
      "    13732797.04939535 13730223.76658109 13726172.42225197]\n",
      "   ...\n",
      "   [13726172.51118699 13730223.92868797 13732797.04939535 ...\n",
      "    13744724.1323631  13741935.04988726 13736806.7308716 ]\n",
      "   [13723624.5321328  13727667.85616194 13730223.76658109 ...\n",
      "    13741935.04988726 13740953.10468148 13736848.12196723]\n",
      "   [13719598.16982594 13723624.60196747 13726172.42225197 ...\n",
      "    13736806.7308716  13736848.12196723 13734925.93097902]]\n",
      "\n",
      "  [[15618034.95784331 15620350.05509955 15620582.50895622 ...\n",
      "    15598513.09105592 15595916.7786068  15591636.41360863]\n",
      "   [15620350.05509955 15624633.4490852  15625802.6210357  ...\n",
      "    15602800.10071388 15600210.54926449 15595920.42758797]\n",
      "   [15620582.50895622 15625802.6210357  15628665.52973107 ...\n",
      "    15605387.74860319 15602803.11843015 15598519.76967184]\n",
      "   ...\n",
      "   [15598513.09105592 15602800.10071388 15605387.74860319 ...\n",
      "    15628475.35939658 15625615.26122024 15620399.04908694]\n",
      "   [15595916.7786068  15600210.54926449 15602803.11843015 ...\n",
      "    15625615.26122024 15624448.09754349 15620167.99739867]\n",
      "   [15591636.41360863 15595920.42758797 15598519.76967184 ...\n",
      "    15620399.04908694 15620167.99739867 15617855.03393712]]\n",
      "\n",
      "  [[11295099.526227   11296585.50240576 11297279.82589691 ...\n",
      "    11254697.69279476 11252722.22658947 11250103.56086085]\n",
      "   [11296585.50240576 11299039.14137498 11300167.31813808 ...\n",
      "    11257329.12945758 11255353.49210274 11252727.73957679]\n",
      "   [11297279.82589691 11300167.31813808 11302109.49568477 ...\n",
      "    11259310.35337134 11257333.36119922 11254707.44633571]\n",
      "   ...\n",
      "   [11254697.69279476 11257329.12945758 11259310.35337134 ...\n",
      "    11302290.16551945 11300352.41656176 11297470.70397457]\n",
      "   [11252722.22658947 11255353.49210274 11257333.36119922 ...\n",
      "    11300352.41656176 11299228.22958721 11296780.01694632]\n",
      "   [11250103.56086085 11252727.73957679 11254707.44633571 ...\n",
      "    11297470.70397457 11296780.01694632 11295298.80787252]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1983586.69191855  1978635.41050362  1962621.87318722 ...\n",
      "     1857101.14060745  1853696.79287965  1849760.07809303]\n",
      "   [ 1978635.41050362  1990172.66628225  1984389.05299497 ...\n",
      "     1861030.53553248  1857606.78086888  1853696.79287965]\n",
      "   [ 1962621.87318722  1984389.05299497  1995317.63480206 ...\n",
      "     1864397.97179546  1861030.53553248  1857101.14060745]\n",
      "   ...\n",
      "   [ 1857101.14060745  1861030.53553248  1864397.97179546 ...\n",
      "     1995317.63480206  1984389.05299497  1962621.87318722]\n",
      "   [ 1853696.79287965  1857606.78086888  1861030.53553248 ...\n",
      "     1984389.05299497  1990172.66628225  1978635.41050362]\n",
      "   [ 1849760.07809303  1853696.79287965  1857101.14060745 ...\n",
      "     1962621.87318722  1978635.41050362  1983586.69191855]]\n",
      "\n",
      "  [[ 4145552.20625889  4140933.95523242  4121715.61926943 ...\n",
      "     3861102.20046133  3853274.65783923  3846127.85488652]\n",
      "   [ 4140933.95523242  4162287.7916645   4159620.5518337  ...\n",
      "     3867291.39901573  3859858.11149554  3853274.65783923]\n",
      "   [ 4121715.61926943  4159620.5518337   4182785.60911929 ...\n",
      "     3874541.2175317   3867291.39901573  3861102.20046133]\n",
      "   ...\n",
      "   [ 3861102.20046133  3867291.39901573  3874541.2175317  ...\n",
      "     4182785.60911929  4159620.5518337   4121715.61926943]\n",
      "   [ 3853274.65783923  3859858.11149554  3867291.39901573 ...\n",
      "     4159620.5518337   4162287.7916645   4140933.95523242]\n",
      "   [ 3846127.85488652  3853274.65783923  3861102.20046133 ...\n",
      "     4121715.61926943  4140933.95523242  4145552.20625889]]\n",
      "\n",
      "  [[12371248.56223731 12378991.74004081 12365524.7570029  ...\n",
      "    11035492.29493285 11025672.6807691  11014462.38222232]\n",
      "   [12378991.74004081 12420159.57753924 12428008.05857988 ...\n",
      "    11045526.90042296 11036273.95552499 11025672.6807691 ]\n",
      "   [12365524.7570029  12428008.05857988 12466145.59021132 ...\n",
      "    11054521.18588263 11045526.90042296 11035492.29493285]\n",
      "   ...\n",
      "   [11035492.29493285 11045526.90042296 11054521.18588263 ...\n",
      "    12466145.59021132 12428008.05857988 12365524.7570029 ]\n",
      "   [11025672.6807691  11036273.95552499 11045526.90042296 ...\n",
      "    12428008.05857988 12420159.57753924 12378991.74004081]\n",
      "   [11014462.38222232 11025672.6807691  11035492.29493285 ...\n",
      "    12365524.7570029  12378991.74004081 12371248.56223731]]]\n",
      "\n",
      "\n",
      " [[[17087175.0150845  17093420.07052512 17096723.7824515  ...\n",
      "    17091291.99509291 17086466.2268807  17078785.98784958]\n",
      "   [17093420.07052512 17100931.61562281 17104824.67090956 ...\n",
      "    17098978.64504295 17094156.50077535 17086470.68538128]\n",
      "   [17096723.7824515  17104824.67090956 17109666.32056706 ...\n",
      "    17103794.83149428 17098980.61576191 17091298.40212097]\n",
      "   ...\n",
      "   [17091291.99509291 17098978.64504295 17103794.83149428 ...\n",
      "    17109620.01580735 17104780.22298953 17096683.65462374]\n",
      "   [17086466.2268807  17094156.50077535 17098980.61576191 ...\n",
      "    17104780.22298953 17100888.58026718 17093381.04395073]\n",
      "   [17078785.98784958 17086470.68538128 17091298.40212097 ...\n",
      "    17096683.65462374 17093381.04395073 17087139.4409361 ]]\n",
      "\n",
      "  [[17990104.05140928 17996824.3328092  17999279.78262109 ...\n",
      "    17986722.29659286 17982630.52854995 17974326.97413252]\n",
      "   [17996824.3328092  18004990.31340092 18008119.13485466 ...\n",
      "    17995036.68507419 17990942.87806146 17982633.3198456 ]\n",
      "   [17999279.78262109 18008119.13485466 18012332.95441595 ...\n",
      "    17999133.04539724 17995034.27257131 17986722.68387467]\n",
      "   ...\n",
      "   [17986722.29659286 17995036.68507419 17999133.04539724 ...\n",
      "    18012366.02992538 18008149.79981429 17999313.2063658 ]\n",
      "   [17982630.52854995 17990942.87806146 17995034.27257131 ...\n",
      "    18008149.79981429 18005017.93697646 17996854.3452967 ]\n",
      "   [17974326.97413252 17982633.3198456  17986722.68387467 ...\n",
      "    17999313.2063658  17996854.3452967  17990135.57809902]]\n",
      "\n",
      "  [[17964546.16761065 17969705.53253216 17972524.61522351 ...\n",
      "    17941450.56698116 17937497.02002231 17931221.18694265]\n",
      "   [17969705.53253216 17975720.91603044 17978913.1756847  ...\n",
      "    17947745.69902268 17943786.06683505 17937505.45942254]\n",
      "   [17972524.61522351 17978913.1756847  17982745.89425419 ...\n",
      "    17951712.88364407 17947749.02895732 17941462.32592003]\n",
      "   ...\n",
      "   [17941450.56698116 17947745.69902268 17951712.88364407 ...\n",
      "    17983561.03360059 17979731.6081799  17973351.30535807]\n",
      "   [17937497.02002231 17943786.06683505 17947749.02895732 ...\n",
      "    17979731.6081799  17976542.35293932 17970534.98863366]\n",
      "   [17931221.18694265 17937505.45942254 17941462.32592003 ...\n",
      "    17973351.30535807 17970534.98863366 17965383.09353144]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1507963.70674358  1513408.82688197  1511635.64267589 ...\n",
      "     1464932.30277585  1458135.84452134  1448071.6721261 ]\n",
      "   [ 1513408.82688197  1526049.73811613  1528666.64836602 ...\n",
      "     1474886.50363707  1468154.39298732  1458135.84452134]\n",
      "   [ 1511635.64267589  1528666.64836602  1538218.84636681 ...\n",
      "     1481500.78655901  1474886.50363707  1464932.30277585]\n",
      "   ...\n",
      "   [ 1464932.30277585  1474886.50363707  1481500.78655901 ...\n",
      "     1538218.84636681  1528666.64836602  1511635.64267589]\n",
      "   [ 1458135.84452134  1468154.39298732  1474886.50363707 ...\n",
      "     1528666.64836602  1526049.73811613  1513408.82688197]\n",
      "   [ 1448071.6721261   1458135.84452134  1464932.30277585 ...\n",
      "     1511635.64267589  1513408.82688197  1507963.70674358]]\n",
      "\n",
      "  [[ 3010242.01608612  3012779.06071507  3002675.34156091 ...\n",
      "     2886222.68075353  2883915.62821989  2875607.50363704]\n",
      "   [ 3012779.06071507  3026690.67186467  3023836.55083427 ...\n",
      "     2894110.57148787  2892053.54755861  2883915.62821989]\n",
      "   [ 3002675.34156091  3023836.55083427  3032058.78265283 ...\n",
      "     2895975.39903111  2894110.57148787  2886222.68075353]\n",
      "   ...\n",
      "   [ 2886222.68075353  2894110.57148787  2895975.39903111 ...\n",
      "     3032058.78265283  3023836.55083427  3002675.34156091]\n",
      "   [ 2883915.62821989  2892053.54755861  2894110.57148787 ...\n",
      "     3023836.55083427  3026690.67186467  3012779.06071507]\n",
      "   [ 2875607.50363704  2883915.62821989  2886222.68075353 ...\n",
      "     3002675.34156091  3012779.06071507  3010242.01608612]]\n",
      "\n",
      "  [[ 8057843.17679306  8054081.7581546   8033167.52270673 ...\n",
      "     7434938.52550533  7447893.13276406  7451580.89870027]\n",
      "   [ 8054081.7581546   8065144.94940358  8053782.47232607 ...\n",
      "     7430957.4172855   7444062.31169526  7447893.13276406]\n",
      "   [ 8033167.52270673  8053782.47232607  8055610.93660852 ...\n",
      "     7417681.10000749  7430957.4172855   7434938.52550533]\n",
      "   ...\n",
      "   [ 7434938.52550533  7430957.4172855   7417681.10000749 ...\n",
      "     8055610.93660852  8053782.47232607  8033167.52270673]\n",
      "   [ 7447893.13276406  7444062.31169526  7430957.4172855  ...\n",
      "     8053782.47232607  8065144.94940358  8054081.7581546 ]\n",
      "   [ 7451580.89870027  7447893.13276406  7434938.52550533 ...\n",
      "     8033167.52270673  8054081.7581546   8057843.17679306]]]\n",
      "\n",
      "\n",
      " [[[ 1361288.3068818   1356308.48095335  1351904.69560929 ...\n",
      "     1344403.55401763  1346413.04016911  1349430.58560549]\n",
      "   [ 1356308.48095335  1353229.39269494  1349762.85256426 ...\n",
      "     1341433.46291419  1343427.34271428  1346414.68361394]\n",
      "   [ 1351904.69560929  1349762.85256426  1347871.38045348 ...\n",
      "     1339449.80742784  1341434.3534486   1344406.0648673 ]\n",
      "   ...\n",
      "   [ 1344403.55401763  1341433.46291419  1339449.80742784 ...\n",
      "     1347881.4137945   1349773.60641278  1351917.24229133]\n",
      "   [ 1346413.04016911  1343427.34271428  1341434.3534486  ...\n",
      "     1349773.60641278  1353240.88911939  1356321.8405535 ]\n",
      "   [ 1349430.58560549  1346414.68361394  1344406.0648673  ...\n",
      "     1351917.24229133  1356321.8405535   1361303.32993447]]\n",
      "\n",
      "  [[ 1329092.4544252   1324341.0286351   1320452.97205686 ...\n",
      "     1306671.79500185  1308281.96481346  1311066.53450206]\n",
      "   [ 1324341.0286351   1321443.93822372  1318522.14220677 ...\n",
      "     1303936.92785846  1305525.96907337  1308282.20668966]\n",
      "   [ 1320452.97205686  1318522.14220677  1317161.2946712  ...\n",
      "     1302354.46191459  1303938.01134942  1306673.13381   ]\n",
      "   ...\n",
      "   [ 1306671.79500185  1303936.92785846  1302354.46191459 ...\n",
      "     1317180.05945397  1318541.81130327  1320472.59875428]\n",
      "   [ 1308281.96481346  1305525.96907337  1303938.01134942 ...\n",
      "     1318541.81130327  1321464.21737789  1324360.99560165]\n",
      "   [ 1311066.53450206  1308282.20668966  1306673.13381    ...\n",
      "     1320472.59875428  1324360.99560165  1329111.60882736]]\n",
      "\n",
      "  [[ 1182715.17476341  1179632.65437899  1176958.88143014 ...\n",
      "     1150464.45219531  1151752.83100346  1153572.62343714]\n",
      "   [ 1179632.65437899  1177558.23689336  1175410.11916945 ...\n",
      "     1148651.30934257  1149937.17544022  1151750.95844675]\n",
      "   [ 1176958.88143014  1175410.11916945  1174085.0829987  ...\n",
      "     1147364.71963092  1148649.87146483  1150461.12716648]\n",
      "   ...\n",
      "   [ 1150464.45219531  1148651.30934257  1147364.71963092 ...\n",
      "     1174001.34997294  1175325.006136    1176872.00110719]\n",
      "   [ 1151752.83100346  1149937.17544022  1148649.87146483 ...\n",
      "     1175325.006136    1177471.45459424  1179543.8814455 ]\n",
      "   [ 1153572.62343714  1151750.95844675  1150461.12716648 ...\n",
      "     1176872.00110719  1179543.8814455   1182623.96039971]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[   80841.90165321    79092.90448289    76977.49579393 ...\n",
      "       66569.29763937    66644.37928489    67317.93144175]\n",
      "   [   79092.90448289    79155.58139177    78203.36090734 ...\n",
      "       65888.95650903    65983.17656286    66644.37928489]\n",
      "   [   76977.49579393    78203.36090734    79072.50426759 ...\n",
      "       65768.81645521    65888.95650903    66569.29763937]\n",
      "   ...\n",
      "   [   66569.29763937    65888.95650903    65768.81645521 ...\n",
      "       79072.50426759    78203.36090734    76977.49579393]\n",
      "   [   66644.37928489    65983.17656286    65888.95650903 ...\n",
      "       78203.36090734    79155.58139177    79092.90448289]\n",
      "   [   67317.93144175    66644.37928489    66569.29763937 ...\n",
      "       76977.49579393    79092.90448289    80841.90165321]]\n",
      "\n",
      "  [[  190886.7701807    188474.55733949   185849.00364475 ...\n",
      "      157048.20811995   156657.3051288    157723.8989927 ]\n",
      "   [  188474.55733949   189381.64170703   188904.70266821 ...\n",
      "      155923.9159554    155569.87306421   156657.3051288 ]\n",
      "   [  185849.00364475   188904.70266821   191816.48079969 ...\n",
      "      156278.12207612   155923.9159554    157048.20811995]\n",
      "   ...\n",
      "   [  157048.20811995   155923.9159554    156278.12207612 ...\n",
      "      191816.48079969   188904.70266821   185849.00364475]\n",
      "   [  156657.3051288    155569.87306421   155923.9159554  ...\n",
      "      188904.70266821   189381.64170703   188474.55733949]\n",
      "   [  157723.8989927    156657.3051288    157048.20811995 ...\n",
      "      185849.00364475   188474.55733949   190886.7701807 ]]\n",
      "\n",
      "  [[  687522.42074585   690068.03760091   692370.98952709 ...\n",
      "      510415.53650134   507390.38832756   506446.68961168]\n",
      "   [  690068.03760091   697729.09820837   703340.94934255 ...\n",
      "      511191.4633141    508222.54677431   507390.38832756]\n",
      "   [  692370.98952709   703340.94934255   713794.87987696 ...\n",
      "      514141.48582852   511191.4633141    510415.53650134]\n",
      "   ...\n",
      "   [  510415.53650134   511191.4633141    514141.48582852 ...\n",
      "      713794.87987696   703340.94934255   692370.98952709]\n",
      "   [  507390.38832756   508222.54677431   511191.4633141  ...\n",
      "      703340.94934255   697729.09820837   690068.03760091]\n",
      "   [  506446.68961168   507390.38832756   510415.53650134 ...\n",
      "      692370.98952709   690068.03760091   687522.42074585]]]]\n",
      "[[[-0.00776844  0.03193292 -0.02190021 ... -0.01967823  0.03001971\n",
      "   -0.00888104]\n",
      "  [-0.01141223  0.01261335  0.02016473 ...  0.01930055  0.01481435\n",
      "   -0.01501347]\n",
      "  [ 0.01339742 -0.02036281  0.0327504  ...  0.03148365 -0.02175744\n",
      "    0.0157307 ]\n",
      "  ...\n",
      "  [ 0.01612403 -0.07226699  0.09574159 ...  0.09574159 -0.07226699\n",
      "    0.01612403]\n",
      "  [-0.00475539 -0.02033391  0.03408606 ...  0.03408606 -0.02033391\n",
      "   -0.00475539]\n",
      "  [-0.04063615 -0.05660783  0.04304323 ...  0.04304328 -0.05660786\n",
      "   -0.04063614]]\n",
      "\n",
      " [[-0.01859845  0.01546722  0.0108962  ...  0.0078561   0.01428418\n",
      "   -0.02116207]\n",
      "  [ 0.00531654  0.0057736  -0.00060638 ... -0.00112536  0.00732128\n",
      "   -0.00220609]\n",
      "  [ 0.01095194 -0.00353982  0.00285532 ... -0.00191663 -0.00148994\n",
      "    0.00316263]\n",
      "  ...\n",
      "  [-0.01622886  0.02497454 -0.01994764 ... -0.01994766  0.02497455\n",
      "   -0.01622886]\n",
      "  [-0.00999878  0.03655502 -0.07536039 ... -0.07536034  0.03655499\n",
      "   -0.00999877]\n",
      "  [-0.03270121 -0.0377052   0.01467869 ...  0.01467865 -0.03770519\n",
      "   -0.03270121]]\n",
      "\n",
      " [[-0.01859822  0.02345282  0.00115298 ...  0.00606191  0.02393539\n",
      "   -0.02102015]\n",
      "  [ 0.00883563 -0.00247924  0.00416388 ... -0.00213191  0.00759602\n",
      "   -0.00169398]\n",
      "  [ 0.00826256  0.00418403  0.00105309 ... -0.00243997  0.00225191\n",
      "    0.00488603]\n",
      "  ...\n",
      "  [ 0.01227053 -0.07772588  0.1630244  ...  0.1630244  -0.07772588\n",
      "    0.01227053]\n",
      "  [ 0.02446056 -0.10246701  0.12106155 ...  0.12106155 -0.10246702\n",
      "    0.02446056]\n",
      "  [-0.02383464 -0.02997095  0.02674616 ...  0.0267462  -0.02997098\n",
      "   -0.02383463]]\n",
      "\n",
      " [[-0.02117638  0.02581447  0.00038692 ... -0.00182418  0.02850038\n",
      "   -0.02232684]\n",
      "  [ 0.00812576 -0.01163149  0.01796988 ...  0.01739769 -0.01133722\n",
      "    0.00797908]\n",
      "  [ 0.00544527 -0.00267384  0.01253947 ...  0.01378071 -0.00394178\n",
      "    0.00615619]\n",
      "  ...\n",
      "  [-0.05062682  0.10451329 -0.10287672 ... -0.10287671  0.10451328\n",
      "   -0.05062682]\n",
      "  [ 0.01820577  0.00172198 -0.04704746 ... -0.04704746  0.00172198\n",
      "    0.01820577]\n",
      "  [-0.01436059 -0.04356252 -0.01837525 ... -0.01837525 -0.04356252\n",
      "   -0.01436059]]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n",
      "(3, 2, 2)\n",
      "[[[[ 7 11 13]\n",
      "   [15 16  4]]\n",
      "\n",
      "  [[10 16 18]\n",
      "   [22 24  6]]]\n",
      "\n",
      "\n",
      " [[[10 16 18]\n",
      "   [22 24  6]]\n",
      "\n",
      "  [[11 18 19]\n",
      "   [25 28  7]]]\n",
      "\n",
      "\n",
      " [[[ 3  5  5]\n",
      "   [ 7  8  2]]\n",
      "\n",
      "  [[ 6 11  8]\n",
      "   [16 20  5]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  4,  1],\n",
       "        [ 4,  9, 16]],\n",
       "\n",
       "       [[ 9, 16,  1],\n",
       "        [16, 16,  1]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.array([[[1,2], [1,2]],\n",
    "              [[3,4], [3,4]],\n",
    "              [[1,4], [4,1]]])\n",
    "print(f1.shape)\n",
    "f1 = f1.reshape(2,2,3)\n",
    "print(f1.T.shape)\n",
    "print(np.dot(f1.T, f1))\n",
    "f1 * f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00324561, -0.00059579, -0.00128021, ..., -0.00578292,\n",
       "         0.01777824, -0.00643502],\n",
       "       [-0.01600889,  0.00809095,  0.03050988, ...,  0.00758871,\n",
       "         0.01989145, -0.01325478],\n",
       "       [ 0.00656672, -0.00490941, -0.00502968, ...,  0.00179324,\n",
       "        -0.00832478,  0.01015856],\n",
       "       ...,\n",
       "       [ 0.0444698 , -0.12427632,  0.18072975, ..., -0.00603139,\n",
       "         0.00686369, -0.03684298],\n",
       "       [-0.0129811 , -0.00030824,  0.00968535, ...,  0.02612797,\n",
       "        -0.07032155,  0.02073493],\n",
       "       [-0.03408313, -0.02110304, -0.00275129, ...,  0.02475028,\n",
       "        -0.04518779, -0.03648413]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Filters/filter\"+str(R), \"rb\") as fp:\n",
    "    h_raisr = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0007075 , -0.00708702, -0.01046391, ...,  0.00033279,\n",
       "        -0.0004557 , -0.00411572],\n",
       "       [-0.00033651, -0.00460817, -0.00756705, ..., -0.00341872,\n",
       "        -0.00238595,  0.00307929],\n",
       "       [-0.0040753 , -0.00427952, -0.00423952, ..., -0.00210784,\n",
       "        -0.00135864, -0.00191929],\n",
       "       ...,\n",
       "       [ 0.05302069, -0.07342937,  0.00305579, ..., -0.17168161,\n",
       "         0.15819626,  0.01565984],\n",
       "       [-0.01224221, -0.0717789 ,  0.15969609, ..., -0.19601314,\n",
       "         0.19350631, -0.05991437],\n",
       "       [-0.15019842,  0.05535512,  0.0566023 , ...,  0.00841502,\n",
       "        -0.01929808,  0.0336716 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_raisr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_matrix = io.loadmat('1000_patch_PCA_matrix.mat')['p']\n",
    "#pca_matrix = np.array(pca_matrix)\n",
    "pca_matrix[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20094993244945833"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(pca_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = joblib.load('2_2000_kmeans.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict([kmeans.cluster_centers_[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89180212,  1.79128627],\n",
       "       [-2.41173289,  1.01900477],\n",
       "       [-1.18390828, -2.8171925 ],\n",
       "       [ 0.1069151 , -0.08437171]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = io.loadmat('2000_patch_mean_matrix.mat')['m']\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Filters/Ckmeans_filter\"+str(2), \"rb\") as fp:\n",
    "    h = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Filters/8x_filter\"+str(2), \"rb\") as fp:\n",
    "    h = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.159237958216096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(h[2,10].reshape(-1, 1), h[3,10].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
